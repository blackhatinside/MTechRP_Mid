{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8742976,"sourceType":"datasetVersion","datasetId":5243179}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Libraries\n# !pip install nilearn\n\nimport nibabel as nib\nimport numpy as np\nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Dropout, Conv2D, MaxPooling2D, UpSampling2D, concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.metrics import MeanIoU\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-22T04:25:36.407830Z","iopub.execute_input":"2024-10-22T04:25:36.408296Z","iopub.status.idle":"2024-10-22T04:25:52.995104Z","shell.execute_reply.started":"2024-10-22T04:25:36.408251Z","shell.execute_reply":"2024-10-22T04:25:52.993609Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Paths and dataset\n\n'''\n    DIRECTORY STRUCTURE INSIDE MY KAGGLE\n\n    home ('../')\n        lib\n            kaggle\n                gcp.py\n        input_png\n            SISS2015_Training\n                augmented\n                    lesions\n                    non_lesions\n                [1-28] folders\n        input\n            siss2015small\n                SISS2015_Training\n                    [1-28] folders\n        working\n        \n\n'''\n\nTRAIN_DATASET_PATH = '../input/siss2015small/SISS2015_Training/'\nPNG_PATH = '../input_png/'\nPNG_TRAIN_DATASET_PATH = '../input_png/SISS2015_Training/'\nAUG_PNG_TRAIN_DATASET_PATH = None\n\ntrain_directories = [f.path+'/' for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\ntrain_ids = train_directories.copy()\ntrain_ids.sort()\n\n# train_test_ids, val_ids = train_test_split(train_ids, test_size=0.2, shuffle=False)\n# train_ids, test_ids = train_test_split(train_test_ids, test_size=0.15, shuffle=False)\n\nVOLUME_SLICES = 153\nVOLUME_START_AT = 0\nIMG_SIZE=192\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:25:52.997089Z","iopub.execute_input":"2024-10-22T04:25:52.997797Z","iopub.status.idle":"2024-10-22T04:25:53.017497Z","shell.execute_reply.started":"2024-10-22T04:25:52.997747Z","shell.execute_reply":"2024-10-22T04:25:53.016132Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"try:\n    os.makedirs(PNG_TRAIN_DATASET_PATH, exist_ok=True)\nexcept FileExistsError as e:\n    print(\"Folder already exists!\")\n\ntry:\n    for i in range(1, 29):\n        os.mkdir(PNG_TRAIN_DATASET_PATH + \"{}/\".format(str(i)))\nexcept FileExistsError as e:\n    print(\"Folder already exists!\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:25:53.019028Z","iopub.execute_input":"2024-10-22T04:25:53.019590Z","iopub.status.idle":"2024-10-22T04:25:53.029554Z","shell.execute_reply.started":"2024-10-22T04:25:53.019550Z","shell.execute_reply":"2024-10-22T04:25:53.028406Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(\"TOTAL TRAINING SAMPLES: \", )\nprint(\"SAMPLE 1: \", train_ids[0])\n\nprint(\"CURRENT WORKING DIRECTORY: \", os.getcwd())\nprint(\"CURRENT WORKING DIRECTORY ITEMS: \", os.listdir('../'))\nprint(\"PNG DATASET DIRECTORY ITEMS: \", os.listdir(PNG_TRAIN_DATASET_PATH))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:25:53.032610Z","iopub.execute_input":"2024-10-22T04:25:53.033656Z","iopub.status.idle":"2024-10-22T04:25:53.046616Z","shell.execute_reply.started":"2024-10-22T04:25:53.033604Z","shell.execute_reply":"2024-10-22T04:25:53.045388Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"TOTAL TRAINING SAMPLES: \nSAMPLE 1:  ../input/siss2015small/SISS2015_Training/1/\nCURRENT WORKING DIRECTORY:  /kaggle/working\nCURRENT WORKING DIRECTORY ITEMS:  ['lib', 'input_png', 'input', 'working']\nPNG DATASET DIRECTORY ITEMS:  ['27', '22', '5', '23', '11', '6', '12', '24', '17', '20', '28', '18', '21', '4', '16', '10', '19', '26', '1', '25', '15', '9', '7', '3', '2', '8', '13', '14']\n","output_type":"stream"}]},{"cell_type":"code","source":"mod_dict = {\n    1: \".MR_DWI.\", \n    2: \".MR_Flair.\", \n    3: \".MR_T1.\", \n    4: \".MR_T2.\", \n    5: \".OT.\" # MASK OUTPUT\n}\n\nTOTAL_TRAINING_SAMPLES = len(train_ids) #28\nnii_counter = 70613\nPADDED_IMG_SIZE = 256  # Target image size\n\ndef pad_image(image, target_size=PADDED_IMG_SIZE):\n    \"\"\"Pad the image to the target size.\"\"\"\n    h, w = image.shape\n    pad_h = (target_size - h) // 2\n    pad_w = (target_size - w) // 2\n\n    padded_image = np.pad(image, \n                         ((pad_h, target_size - h - pad_h), \n                          (pad_w, target_size - w - pad_w)), \n                         mode='constant', constant_values=0)\n    return padded_image\n\ndef nii_to_png():\n    global nii_counter\n    global TOTAL_TRAINING_SAMPLES\n    for i in range(1, TOTAL_TRAINING_SAMPLES + 1):\n        if i == 15:\n            nii_counter = 70707\n        if i == 16:\n            nii_counter = 70717\n        if i == 19:\n            nii_counter = 70747\n        if i == 20:\n            nii_counter = 70761\n        for j in range(1, len(mod_dict) + 1):\n            if i == 16 and j == 3:\n                nii_counter = 70725\n            if i == 19 and j == 2:\n                nii_counter = 70750\n            if i == 19 and j == 3:\n                nii_counter = 70753\n            if i == 19 and j == 5:\n                nii_counter = 70758\n            if i == 20 and j == 2:\n                nii_counter = 70768\n            sample_path = \"{}/VSD.Brain.XX.O{}{}\".format(str(i), mod_dict[j], str(nii_counter))\n            file_name = \"/VSD.Brain.XX.O{}\".format(mod_dict[j]) + str(nii_counter) + \".nii\"\n            data_path = os.path.join(TRAIN_DATASET_PATH + sample_path + file_name)\n#             print(i, data_path)\n            if j != 4:\n                nii_counter += 1\n            else:\n                nii_counter += 2\n\n            if os.path.exists(data_path):\n                mri_image = nib.load(data_path).get_fdata()\n#                 print(\"Total Slices: \", i, mri_image.shape[-1])\n                for curr_slice in range(mri_image.shape[-1]): # Slice Values (153, 154)\n                    slice_data = mri_image[..., curr_slice]\n                    slice_data = pad_image(slice_data)\n                    if i == 14 and curr_slice == 66: # Test Sample\n                        plt.imshow(slice_data, cmap='gray')\n                    sample_path = \"{}/VSD.Brain.XX.O{}{}\".format(str(i), mod_dict[j], str(nii_counter - 1 if j != 4 else 2))\n                    file_name = \"{}_{}_slice_{}.png\".format(i, j, curr_slice + 1) # mod_dict[j][1:-1]\n#                     png_path = os.path.join(PNG_TRAIN_DATASET_PATH + sample_path)\n                    png_path = \"{}{}/\".format(PNG_TRAIN_DATASET_PATH, i)\n                    if i == 1 and j == 1 and curr_slice == 1: # Test Sample\n                        print(\"Path: \", png_path)\n                        print(\"File Name: \", file_name)\n                        print(\"File Name with Path: \", png_path + file_name)\n                    try:\n                        plt.imsave(png_path + file_name, slice_data, cmap='gray')\n                        if i == 1 and j == 1 and curr_slice == 1: # Test Sample\n                            # Path to the image\n                            image_path = '../input_png/SISS2015_Training/1/1_1_slice_2.png'\n                            # Load the image using OpenCV\n                            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n                            # Check if the image was loaded successfully\n                            if image is not None:\n                                # Print the dimensions of the image\n                                print(f\"Dimensions of the image {image_path}: {image.shape}\")\n                            else:\n                                print(f\"Failed to load the image. Please check the file path: {image_path}\")\n                        pass\n                    except Exception as e:\n                        print(\"Error: \", e)\n            else:\n                print(f\"File not found: {data_path}\")\n        print(\"Saved all PNGs for sample \", i)\n        if i == 1 or i == 28:\n            print(\"Total PNGs for sample {}: \".format(i), len(os.listdir(png_path)))\n        pass\n#         print(i, end = \" \")\n        \nnii_to_png()  # png with dims (256 * 256) saved in RGBA format [Red, Green, Blue, Alpha]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:25:53.048348Z","iopub.execute_input":"2024-10-22T04:25:53.049296Z","iopub.status.idle":"2024-10-22T04:29:55.243188Z","shell.execute_reply.started":"2024-10-22T04:25:53.049250Z","shell.execute_reply":"2024-10-22T04:29:55.241823Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Path:  ../input_png/SISS2015_Training/1/\nFile Name:  1_1_slice_2.png\nFile Name with Path:  ../input_png/SISS2015_Training/1/1_1_slice_2.png\nDimensions of the image ../input_png/SISS2015_Training/1/1_1_slice_2.png: (256, 256)\nSaved all PNGs for sample  1\nTotal PNGs for sample 1:  770\nSaved all PNGs for sample  2\nSaved all PNGs for sample  3\nSaved all PNGs for sample  4\nSaved all PNGs for sample  5\nSaved all PNGs for sample  6\nSaved all PNGs for sample  7\nSaved all PNGs for sample  8\nSaved all PNGs for sample  9\nSaved all PNGs for sample  10\nSaved all PNGs for sample  11\nSaved all PNGs for sample  12\nSaved all PNGs for sample  13\nSaved all PNGs for sample  14\nSaved all PNGs for sample  15\nSaved all PNGs for sample  16\nSaved all PNGs for sample  17\nSaved all PNGs for sample  18\nSaved all PNGs for sample  19\nSaved all PNGs for sample  20\nSaved all PNGs for sample  21\nSaved all PNGs for sample  22\nSaved all PNGs for sample  23\nSaved all PNGs for sample  24\nSaved all PNGs for sample  25\nSaved all PNGs for sample  26\nSaved all PNGs for sample  27\nSaved all PNGs for sample  28\nTotal PNGs for sample 28:  770\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAa4AAAGiCAYAAAC/NyLhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAld0lEQVR4nO3de1BUZ57G8QcQWg02iFwaRjGg8RZQM14IuZipwHIZy42jtavGrTVuSksHUvESZ5ZURcfszLLlzCS7yTpJzVYmztYkJuOWJqsVnWVRIRo0kcRKxEjEMkEjDRFDgzdu/e4fs3ZNR1RAoH3h+6l6q+hz3nPO77zp9kmffvt0kDHGCAAASwQHugAAALqC4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFglYMG1efNm3X333Ro8eLDS0tL04YcfBqoUAIBFAhJcb7/9ttasWaMNGzbo448/1pQpU5Sdna26urpAlAMAsEhQIG6ym5aWphkzZujf//3fJUler1ejRo3SU089pX/8x3/s63IAABYZ1NcHbGlpUXl5uQoKCnzLgoODlZmZqbKysg63aW5uVnNzs++x1+vVhQsXNGLECAUFBfV6zQCAnmWMUVNTkxISEhQc3LWLf30eXOfPn1d7e7vi4uL8lsfFxenEiRMdblNYWKiNGzf2RXkAgD505swZjRw5skvbWDGrsKCgQB6Px9eqq6sDXRIAoAcMGzasy9v0+Tuu6OhohYSEqLa21m95bW2tXC5Xh9s4HA45HI6+KA8A0Ie683FPn7/jCgsL07Rp01RcXOxb5vV6VVxcrPT09L4uBwBgmT5/xyVJa9as0ZIlSzR9+nTNnDlT//qv/6pLly5p6dKlgSgHAGCRgATXggUL9M0332j9+vVyu92aOnWq9uzZc92EDQAAvisg3+O6XY2NjYqIiAh0GQCA2+TxeOR0Oru0jRWzCgEAuIbgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWIXgAgBYheACAFiF4AIAWKXHg+tnP/uZgoKC/NqECRN8669evaq8vDyNGDFC4eHhmj9/vmpra3u6DABAP9Ur77juvfde1dTU+NqBAwd861avXq2dO3dq27ZtKikp0blz5zRv3rzeKAMA0A8N6pWdDhokl8t13XKPx6PXXntNb775ph599FFJ0uuvv66JEyfq0KFDuv/++3ujHABAP9Ir77hOnjyphIQEJScna/HixaqurpYklZeXq7W1VZmZmb6+EyZMUGJiosrKynqjFABAP9Pj77jS0tK0ZcsWjR8/XjU1Ndq4caMefvhhHTt2TG63W2FhYYqMjPTbJi4uTm63+4b7bG5uVnNzs+9xY2NjT5cNALBEjwdXbm6u7+/JkycrLS1No0eP1h//+EcNGTKkW/ssLCzUxo0be6pEAIDFen06fGRkpMaNG6eqqiq5XC61tLSooaHBr09tbW2Hn4ldU1BQII/H42tnzpzp5aoBAHeqXg+uixcv6tSpU4qPj9e0adMUGhqq4uJi3/rKykpVV1crPT39hvtwOBxyOp1+DQAwMPX4pcJnnnlGc+bM0ejRo3Xu3Dlt2LBBISEhWrRokSIiIvTkk09qzZo1ioqKktPp1FNPPaX09HRmFAIAOqXHg+vs2bNatGiR6uvrFRMTo4ceekiHDh1STEyMJOnFF19UcHCw5s+fr+bmZmVnZ+s3v/lNT5cBAOingowxJtBFdFVjY6MiIiICXQYA4DZ5PJ4uf/zDvQoBAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFbpcnCVlpZqzpw5SkhIUFBQkN555x2/9cYYrV+/XvHx8RoyZIgyMzN18uRJvz4XLlzQ4sWL5XQ6FRkZqSeffFIXL168rRMBAAwMXQ6uS5cuacqUKdq8eXOH6zdt2qSXXnpJr776qg4fPqy77rpL2dnZunr1qq/P4sWLVVFRoaKiIu3atUulpaVavnx5988CADBwmNsgyezYscP32Ov1GpfLZX75y1/6ljU0NBiHw2G2bt1qjDHm+PHjRpL56KOPfH12795tgoKCzNdff92p43o8HiOJRqPRaJY3j8fT5ezp0c+4Tp8+LbfbrczMTN+yiIgIpaWlqaysTJJUVlamyMhITZ8+3dcnMzNTwcHBOnz4cE+WAwDohwb15M7cbrckKS4uzm95XFycb53b7VZsbKx/EYMGKSoqytfnu5qbm9Xc3Ox73NjY2JNlAwAsYsWswsLCQkVERPjaqFGjAl0SACBAejS4XC6XJKm2ttZveW1trW+dy+VSXV2d3/q2tjZduHDB1+e7CgoK5PF4fO3MmTM9WTYAwCI9GlxJSUlyuVwqLi72LWtsbNThw4eVnp4uSUpPT1dDQ4PKy8t9ffbu3Suv16u0tLQO9+twOOR0Ov0aAGBg6vJnXBcvXlRVVZXv8enTp3X06FFFRUUpMTFRq1at0s9//nPdc889SkpK0nPPPaeEhATNnTtXkjRx4kTl5ORo2bJlevXVV9Xa2qr8/HwtXLhQCQkJPXZiAIB+qqvTEPft29fhlMYlS5YYY/48Jf65554zcXFxxuFwmIyMDFNZWem3j/r6erNo0SITHh5unE6nWbp0qWlqaup0DUyHp9FotP7RujMdPsgYY2SZxsZGRUREBLoMAMBt8ng8Xf74x4pZhQAAXENwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCs0uXgKi0t1Zw5c5SQkKCgoCC98847fuufeOIJBQUF+bWcnBy/PhcuXNDixYvldDoVGRmpJ598UhcvXrytEwEADAxdDq5Lly5pypQp2rx58w375OTkqKamxte2bt3qt37x4sWqqKhQUVGRdu3apdLSUi1fvrzr1QMABpxBXd0gNzdXubm5N+3jcDjkcrk6XPf5559rz549+uijjzR9+nRJ0ssvv6wf/vCH+tWvfqWEhISulgQMeLGxsRo1atQt+zU0NOjUqVNd2ndERITGjh3b3dIkSe3t7frss8/U3t5+W/sBJEnmNkgyO3bs8Fu2ZMkSExERYWJiYsy4cePMihUrzPnz533rX3vtNRMZGem3TWtrqwkJCTHbt2/v8DhXr141Ho/H186cOWMk0Wi0/2+rVq3q1Gt2x44dXd73Y4891qV/FzrS1NRkoqKiAj5OtDuveTyeLj+fuvyO61ZycnI0b948JSUl6dSpU3r22WeVm5ursrIyhYSEyO12KzY21m+bQYMGKSoqSm63u8N9FhYWauPGjT1dKmCt3/72t7r33nt9jzt7pWLWrFk6ePBgh+tqa2v1N3/zN2pvb9f48eP1u9/9TpIUFRV12/UOHTpUu3fvVltbm9/yL774QkuXLr3t/WNg6fHgWrhwoe/v1NRUTZ48WWPGjNH+/fuVkZHRrX0WFBRozZo1vseNjY2duiwC9DfDhw/XrFmz9Mgjj2jcuHFd3j4qKkoPPPBAh+vOnz+vv/7rv5bX61VycvIN+3VHcHCwZs6ced3yIUOG9NgxMHD0eHB9V3JysqKjo1VVVaWMjAy5XC7V1dX59Wlra9OFCxdu+LmYw+GQw+Ho7VKBO1pQUJDGjx9/3UzenhIdHa3t27f3yr6BntTr3+M6e/as6uvrFR8fL0lKT09XQ0ODysvLfX327t0rr9ertLS03i4HsNbmzZu1bdu2QJcBBFyX33FdvHhRVVVVvsenT5/W0aNHFRUVpaioKG3cuFHz58+Xy+XSqVOn9JOf/ERjx45Vdna2JGnixInKycnRsmXL9Oqrr6q1tVX5+flauHAhMwqB73jooYc0ZcoUSdIDDzygkSNHBriinhUTE6O8vDzt2LFD586dC3Q5sEVXZ3Ps27evw5khS5YsMZcvXzZZWVkmJibGhIaGmtGjR5tly5YZt9vtt4/6+nqzaNEiEx4ebpxOp1m6dKlpamrqdA0ejyfgM2FotN5qoaGhJjw83ISHh5vf/OY3XX2JWik7O9sMHjw44GNP6/vWnVmFQcYYI8s0NjYqIiIi0GUAvWLlypX6xS9+IenPs/EGwue7TU1Neu+99/wmd2Fg8Hg8cjqdXdqm1ydnALi1yZMn6+/+7u8kSTNmzNDw4cMDXFHf+sMf/qCioqJAlwFLEFxAgISFhSkuLk7Snz+/WrduXYArCpy33npLpaWlt+wXFRWlu+66y2+ZMUZut/u674ih/yK4gAD5/ve/7/vHOjiYH2rojBdeeEGPP/643zJjjFJTU/XFF18EqCr0NYILCJDg4GCFhoYGuow73sKFCzV37lxJ0v3339/hmL344otqampSc3Oz8vPz1dTU1MdVoi8RXEAfCgsL06RJkxQcHKzx48cHupw7xrhx427400ZZWVlasGDBTbf/4Q9/KElqbm7Wf/7nf+rbb79VS0uLKioqdKP5Z5MmTdLgwYM7XPfVV1+pvr6+C2eAvsSsQqAPJScn64svvlBISEigS+n3ampqdPfdd6ulpeW6dUFBQaqoqNDEiRM73Hbp0qXasmVLL1cIqXuzCrmwDvSy8PBw/elPf9L777+vt99+m9DqI9HR0SouLvbd/OC7goKC+rgi9BQuFQK9bNCgQXrggQcUHh4e6FIGlNDQUD300EPX/RpFdHS07r///pv+95g6dapmzZrVqZmO6HsEF4ABITg4WF6vV/fdd5/efffdm87kfPrpp5WRkaGpU6fy45d3IC4VAuj3xo8fr8rKSt1///06ePCgxo8ff8tfgh43bpxOnDjRoz/vgp7BOy6gF02dOlUZGRlMew+gzMxMjRs3TmPHjtXChQt13333SdItL92GhYVp7NixWrBggUaMGKGdO3f2RbnoBGYVAr1o3bp12rRpU6DLwG3at2+f5syZI+nPvx/Y3Nwc4Ir6D2YVAkAvePjhh1VdXa3q6mr96le/CnQ5Ax7BBQC3MGjQIN9vDj7yyCP6p3/6p+vumYi+Q3ABvaipqUk1NTU3vHsD7JOamqpnnnmG4AogggvoRb/97W81depUXbp0KdClAP0GwQX0Iq/X2+EthwB0H8EFALAKwQUAsArBBQBdsHv3bv3VX/2Vvv3220CXMmBx5wygFyUnJ2v69OncEb6fKC0t1f/8z//owIEDgS5lQCO4gF40b948bdq0iZ/QsNi1rzIYY7Ry5UodP348wBWBS4VAL3rttdc0c+bMG/66L+58//AP/6AJEyZo4sSJqqqqCnQ5EO+4gF717bffqqKiQr/73e/06KOPKiUlJdAl4SauXLmiN998U21tbb5lhw4d0hdffBHAqvBd3GQX6CMvvfSSnnrqqUCXgRtobW3V2bNnNXHiRG6i24e4yS4AdNMLL7ygadOmEVoW4FIh0Ed27typ5uZmrV27lskad4gjR45o+/btkqT333+fKe6W4FIh0IcSExN18OBBRUdHa/DgwYEuZ0Bqbm5WfX29JGnr1q165plnAlzRwNadS4W84wL6UHV1tcaMGaP/+q//8v0wIfrW+++/r9mzZ0uS2tvbA1wNuoPgAvpYS0uLfv3rX+uTTz7R+vXrA11Orzh69Kh+/etfS5IyMzO1ZMmSHj/Gz3/+c1VWVvotCw0N1b/9279p2LBhamho0OrVq/1mCErS119/zY2PLUdwAQFQUlKi1tbWfhVcV65c0cmTJyVJBw4c0B/+8AdJfw7q++67r8eP984776i8vNxvmcPh0JIlSzR8+HB98803euONN9Ta2trjx0Zg8RkXECAPPPCADh48GOgyeszHH3+sadOmBboMWIbPuAAExPPPP6///u//DnQZGCD4HhcQIBcuXNDu3bvl8XgCXUq3Xb16VX/6059UXFx83WU7oLdwqRAIsMOHD2vGjBnWfLfrL//JOHPmjMaOHcvnSOg27pwBWOhv//ZvtXr16kCX0SlvvvmmJk6c6GuPPvoooYU+x2dcQIB99dVX+vrrrwNdhp/z589rx44d1y3ft2/fdVPQgb5GcAF3gPb2dl25ckWDBw/us0uGbW1tN3y3dOLECS1fvrxP6gC6is+4gDtAWFiYoqKi9NFHH2nkyJF9csz/+I//0LPPPtvhura2NjU0NPRJHRjYmA4PWKqlpUV1dXXatGmTIiIi5HA49JOf/ERhYWFqaGjQiy++KK/Xe912wcHBWr16tSIjI7t8zCtXruj8+fM9UD3Qtwgu4A7h9Xr18ssvS5KGDRumBQsWKDw8XNXV1frFL37R4X31QkJCNHv2bI0aNeq65bGxsTc81jfffGP1NHwMbFwqBO5QYWFhvr9vdm+9v+x3TWJiok6cOKGQkJDr1rW3tyslJUUnT57kJrMIOC4VAv1IZ28E21G/mpoaPfHEEx1O9DDG6OzZs4QWrMU7LgBAwPAFZABAv0dwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCsQnABAKxCcAEArEJwAQCs0qXgKiws1IwZMzRs2DDFxsZq7ty5qqys9Otz9epV5eXlacSIEQoPD9f8+fNVW1vr16e6ulqzZ8/W0KFDFRsbq3Xr1qmtre32zwYA0O91KbhKSkqUl5enQ4cOqaioSK2trcrKytKlS5d8fVavXq2dO3dq27ZtKikp0blz5zRv3jzf+vb2ds2ePVstLS364IMP9Pvf/15btmzR+vXre+6sAAD9l7kNdXV1RpIpKSkxxhjT0NBgQkNDzbZt23x9Pv/8cyPJlJWVGWOMee+990xwcLBxu92+Pq+88opxOp2mubm5U8f1eDxGEo1Go9Esbx6Pp8vZc1ufcXk8HklSVFSUJKm8vFytra3KzMz09ZkwYYISExNVVlYmSSorK1Nqaqri4uJ8fbKzs9XY2KiKiooOj9Pc3KzGxka/BgAYmLodXF6vV6tWrdKDDz6olJQUSZLb7VZYWJgiIyP9+sbFxcntdvv6/GVoXVt/bV1HCgsLFRER4WujRo3qbtkAAMt1O7jy8vJ07NgxvfXWWz1ZT4cKCgrk8Xh87cyZM71+TADAnWlQdzbKz8/Xrl27VFpaqpEjR/qWu1wutbS0qKGhwe9dV21trVwul6/Phx9+6Le/a7MOr/X5LofDIYfD0Z1SAQD9TJfecRljlJ+frx07dmjv3r1KSkryWz9t2jSFhoaquLjYt6yyslLV1dVKT0+XJKWnp+uzzz5TXV2dr09RUZGcTqcmTZp0O+cCABgIujKTY+XKlSYiIsLs37/f1NTU+Nrly5d9fVasWGESExPN3r17zZEjR0x6erpJT0/3rW9razMpKSkmKyvLHD161OzZs8fExMSYgoKCTtfBrEIajUbrH607swq7FFw3OvDrr7/u63PlyhXz4x//2AwfPtwMHTrU/OhHPzI1NTV++/nyyy9Nbm6uGTJkiImOjjZr1641ra2tna6D4KLRaLT+0boTXEH/H0hWaWxsVERERKDLAADcJo/HI6fT2aVtuFchAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqBBcAwCoEFwDAKgQXAMAqXQquwsJCzZgxQ8OGDVNsbKzmzp2ryspKvz4/+MEPFBQU5NdWrFjh16e6ulqzZ8/W0KFDFRsbq3Xr1qmtre32zwYA0O8N6krnkpIS5eXlacaMGWpra9Ozzz6rrKwsHT9+XHfddZev37Jly/T888/7Hg8dOtT3d3t7u2bPni2Xy6UPPvhANTU1+vu//3uFhobqn//5n3vglAAA/Zq5DXV1dUaSKSkp8S175JFHzNNPP33Dbd577z0THBxs3G63b9krr7xinE6naW5u7tRxPR6PkUSj0Wg0y5vH4+ly9tzWZ1wej0eSFBUV5bf8jTfeUHR0tFJSUlRQUKDLly/71pWVlSk1NVVxcXG+ZdnZ2WpsbFRFRUWHx2lublZjY6NfAwAMTF26VPiXvF6vVq1apQcffFApKSm+5Y8//rhGjx6thIQEffrpp/rpT3+qyspKbd++XZLkdrv9QkuS77Hb7e7wWIWFhdq4cWN3SwUA9CPdDq68vDwdO3ZMBw4c8Fu+fPly39+pqamKj49XRkaGTp06pTFjxnTrWAUFBVqzZo3vcWNjo0aNGtW9wgEAVuvWpcL8/Hzt2rVL+/bt08iRI2/aNy0tTZJUVVUlSXK5XKqtrfXrc+2xy+XqcB8Oh0NOp9OvAQAGpi4FlzFG+fn52rFjh/bu3aukpKRbbnP06FFJUnx8vCQpPT1dn332merq6nx9ioqK5HQ6NWnSpK6UAwAYiLoyk2PlypUmIiLC7N+/39TU1Pja5cuXjTHGVFVVmeeff94cOXLEnD592rz77rsmOTnZzJo1y7ePtrY2k5KSYrKysszRo0fNnj17TExMjCkoKOh0HcwqpNFotP7RujOrsEvBdaMDv/7668YYY6qrq82sWbNMVFSUcTgcZuzYsWbdunXXFfbll1+a3NxcM2TIEBMdHW3Wrl1rWltbO10HwUWj0Wj9o3UnuIL+P5Cs0tjYqIiIiECXAQC4TR6Pp8vzFqy8V6GFWQsA6EB3/j23MriampoCXQIAoAd0599zKy8Ver1eVVZWatKkSTpz5gzT4ztw7btujE/HGJ+bY3xujTG6uVuNjzFGTU1NSkhIUHBw195DdfsLyIEUHBys733ve5LE97pugfG5Ocbn5hifW2OMbu5m49PduQpWXioEAAxcBBcAwCrWBpfD4dCGDRvkcDgCXcodifG5Ocbn5hifW2OMbq43x8fKyRkAgIHL2ndcAICBieACAFiF4AIAWIXgAgBYxcrg2rx5s+6++24NHjxYaWlp+vDDDwNdUkD87Gc/U1BQkF+bMGGCb/3Vq1eVl5enESNGKDw8XPPnz7/uRzz7m9LSUs2ZM0cJCQkKCgrSO++847feGKP169crPj5eQ4YMUWZmpk6ePOnX58KFC1q8eLGcTqciIyP15JNP6uLFi314Fr3nVuPzxBNPXPecysnJ8evTX8ensLBQM2bM0LBhwxQbG6u5c+eqsrLSr09nXlPV1dWaPXu2hg4dqtjYWK1bt05tbW19eSq9pjNj9IMf/OC659CKFSv8+tzuGFkXXG+//bbWrFmjDRs26OOPP9aUKVOUnZ3t98OUA8m9996rmpoaXztw4IBv3erVq7Vz505t27ZNJSUlOnfunObNmxfAanvfpUuXNGXKFG3evLnD9Zs2bdJLL72kV199VYcPH9Zdd92l7OxsXb161ddn8eLFqqioUFFRkXbt2qXS0lItX768r06hV91qfCQpJyfH7zm1detWv/X9dXxKSkqUl5enQ4cOqaioSK2trcrKytKlS5d8fW71mmpvb9fs2bPV0tKiDz74QL///e+1ZcsWrV+/PhCn1OM6M0aStGzZMr/n0KZNm3zremSMuvxDKAE2c+ZMk5eX53vc3t5uEhISTGFhYQCrCowNGzaYKVOmdLiuoaHBhIaGmm3btvmWff7550aSKSsr66MKA0uS2bFjh++x1+s1LpfL/PKXv/Qta2hoMA6Hw2zdutUYY8zx48eNJPPRRx/5+uzevdsEBQWZr7/+us9q7wvfHR9jjFmyZIl57LHHbrjNQBqfuro6I8mUlJQYYzr3mnrvvfdMcHCwcbvdvj6vvPKKcTqdprm5uW9PoA98d4yMMeaRRx4xTz/99A236YkxsuodV0tLi8rLy5WZmelbFhwcrMzMTJWVlQWwssA5efKkEhISlJycrMWLF6u6ulqSVF5ertbWVr+xmjBhghITEwfsWJ0+fVput9tvTCIiIpSWluYbk7KyMkVGRmr69Om+PpmZmQoODtbhw4f7vOZA2L9/v2JjYzV+/HitXLlS9fX1vnUDaXw8Ho8kKSoqSlLnXlNlZWVKTU1VXFycr092drYaGxtVUVHRh9X3je+O0TVvvPGGoqOjlZKSooKCAl2+fNm3rifGyKqb7J4/f17t7e1+JyxJcXFxOnHiRICqCpy0tDRt2bJF48ePV01NjTZu3KiHH35Yx44dk9vtVlhYmCIjI/22iYuLk9vtDkzBAXbtvDt6/lxb53a7FRsb67d+0KBBioqKGhDjlpOTo3nz5ikpKUmnTp3Ss88+q9zcXJWVlSkkJGTAjI/X69WqVav04IMPKiUlRZI69Zpyu90dPr+uretPOhojSXr88cc1evRoJSQk6NNPP9VPf/pTVVZWavv27ZJ6ZoysCi74y83N9f09efJkpaWlafTo0frjH/+oIUOGBLAy2GrhwoW+v1NTUzV58mSNGTNG+/fvV0ZGRgAr61t5eXk6duyY32fG8HejMfrLzztTU1MVHx+vjIwMnTp1SmPGjOmRY1t1qTA6OlohISHXzeKpra2Vy+UKUFV3jsjISI0bN05VVVVyuVxqaWlRQ0ODX5+BPFbXzvtmzx+Xy3XdRJ+2tjZduHBhQI5bcnKyoqOjVVVVJWlgjE9+fr527dqlffv2aeTIkb7lnXlNuVyuDp9f19b1Fzcao46kpaVJkt9z6HbHyKrgCgsL07Rp01RcXOxb5vV6VVxcrPT09ABWdme4ePGiTp06pfj4eE2bNk2hoaF+Y1VZWanq6uoBO1ZJSUlyuVx+Y9LY2KjDhw/7xiQ9PV0NDQ0qLy/39dm7d6+8Xq/vBTiQnD17VvX19YqPj5fUv8fHGKP8/Hzt2LFDe/fuVVJSkt/6zrym0tPT9dlnn/mFe1FRkZxOpyZNmtQ3J9KLbjVGHTl69Kgk+T2HbnuMujmZJGDeeust43A4zJYtW8zx48fN8uXLTWRkpN8MlYFi7dq1Zv/+/eb06dPm4MGDJjMz00RHR5u6ujpjjDErVqwwiYmJZu/evebIkSMmPT3dpKenB7jq3tXU1GQ++eQT88knnxhJ5oUXXjCffPKJ+eqrr4wxxvzLv/yLiYyMNO+++6759NNPzWOPPWaSkpLMlStXfPvIyckx9913nzl8+LA5cOCAueeee8yiRYsCdUo96mbj09TUZJ555hlTVlZmTp8+bf73f//XfP/73zf33HOPuXr1qm8f/XV8Vq5caSIiIsz+/ftNTU2Nr12+fNnX51avqba2NpOSkmKysrLM0aNHzZ49e0xMTIwpKCgIxCn1uFuNUVVVlXn++efNkSNHzOnTp827775rkpOTzaxZs3z76Ikxsi64jDHm5ZdfNomJiSYsLMzMnDnTHDp0KNAlBcSCBQtMfHy8CQsLM9/73vfMggULTFVVlW/9lStXzI9//GMzfPhwM3ToUPOjH/3I1NTUBLDi3rdv3z4j6bq2ZMkSY8yfp8Q/99xzJi4uzjgcDpORkWEqKyv99lFfX28WLVpkwsPDjdPpNEuXLjVNTU0BOJued7PxuXz5ssnKyjIxMTEmNDTUjB492ixbtuy6/ynsr+PT0bhIMq+//rqvT2deU19++aXJzc01Q4YMMdHR0Wbt2rWmtbW1j8+md9xqjKqrq82sWbNMVFSUcTgcZuzYsWbdunXG4/H47ed2x4ifNQEAWMWqz7gAACC4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFYhuAAAViG4AABWIbgAAFb5P2UYgWJ4oInSAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"import glob\nimport re\n\ndef is_black_image(image_path):\n    return True  # UNCOMMENT TO DEBUG\n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale mode (so pixel values range from 0 to 255)\n    # Check if the image is loaded correctly\n    if img is None:\n        print(f\"Failed to load image: {image_path}\")\n        return False  # Return False if the image could not be loaded\n    # If the image has multiple channels (RGBA), extract only the RGB channels\n    if img.shape[-1] == 4:\n        rgb_img = img[:, :, :3]  # Ignore the alpha channel\n    else:\n        rgb_img = img  # If already RGB or grayscale, keep it as is\n    # Check if all pixel values in the RGB channels are zero (black)\n    if np.all(rgb_img == 0):\n        return True  # The image is fully black\n    else:\n        return False  # The image contains non-black pixels (e.g., white pixels)\n\n# Function to load images from a specific path\ndef load_images(image_paths):\n    images = []\n    for img_path in image_paths:\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        if img is not None and is_black_image(img_path):\n            images.append(img)\n    return np.array(images)\n\n# Helper function to extract modality and slice numbers\ndef extract_modality_and_slice(path):\n    # Use regex to extract modality and slice numbers from the file name\n    match = re.search(r'_(\\d)_(?:slice_)(\\d+)', path)\n    if match:\n        modality = int(match.group(1))  # Extract modality (1, 2, 3, 4)\n        slice_num = int(match.group(2))  # Extract slice number\n        return modality, slice_num\n    return -1, -1  # Default in case no match is found\n\n# Sort function to first sort by modality, then by slice number within each modality\ndef sort_by_modality_and_slice(paths):\n    return sorted(paths, key=lambda x: extract_modality_and_slice(x))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:55.244603Z","iopub.execute_input":"2024-10-22T04:29:55.244991Z","iopub.status.idle":"2024-10-22T04:29:55.256240Z","shell.execute_reply.started":"2024-10-22T04:29:55.244952Z","shell.execute_reply":"2024-10-22T04:29:55.254781Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport glob\n\n# Load modality and mask images\nmod_img_path_pattern = \"../input_png/SISS2015_Training/1/1_[1-4]_slice_*.png\"\nmsk_img_path_pattern = \"../input_png/SISS2015_Training/1/1_5_slice_*.png\"\n\nabs_mod_img_paths = glob.glob(mod_img_path_pattern)\nabs_mod_img_paths = sort_by_modality_and_slice(abs_mod_img_paths)\n\nabs_msk_img_paths = glob.glob(msk_img_path_pattern)\nabs_msk_img_paths = sort_by_modality_and_slice(abs_msk_img_paths)\n\n# Initialize lists to store valid modality and mask images\nvalid_modality_images = []\nvalid_mask_images = []\n\n# Iterate through the modality and mask images\nfor mod_path, msk_path in zip(abs_mod_img_paths, abs_msk_img_paths):\n    # Load images\n    mod_img = cv2.imread(mod_path, cv2.IMREAD_GRAYSCALE)  # Load modality image\n    msk_img = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)  # Load mask image\n\n    # Check if the modality image is not fully black (not all pixels are 0)\n    if not np.all(mod_img == 0):\n        valid_modality_images.append(mod_img)  # Keep valid modality images\n        valid_mask_images.append(msk_img)  # Keep corresponding mask\n\n# Convert valid images back to NumPy arrays (optional)\nif valid_modality_images:\n    mod_filtered = np.stack(valid_modality_images, axis=0)  # Stack along a new axis\nelse:\n    mod_filtered = np.empty((0, 256, 256))  # No valid slices\n\nif valid_mask_images:\n    msk_filtered = np.stack(valid_mask_images, axis=0)\nelse:\n    msk_filtered = np.empty((0, 256, 256))  # No valid slices\n\n# Print the result\nprint(f\"Original modality images: {len(abs_mod_img_paths)}, valid modality images: {mod_filtered.shape}\")\nprint(f\"Original mask images: {len(abs_msk_img_paths)}, valid mask images: {msk_filtered.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:55.276536Z","iopub.execute_input":"2024-10-22T04:29:55.276945Z","iopub.status.idle":"2024-10-22T04:29:55.673684Z","shell.execute_reply.started":"2024-10-22T04:29:55.276906Z","shell.execute_reply":"2024-10-22T04:29:55.672372Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Original modality images: 616, valid modality images: (136, 256, 256)\nOriginal mask images: 154, valid mask images: (136, 256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\n\ndef print_pixel_value_at_coordinates(image_path, coordinates):\n    \"\"\"\n    Print the RGB(A) values at specified coordinates in the image.\n    :param image_path: Path to the image file.\n    :param coordinates: List of (x, y) tuples representing the pixel coordinates to check.\n    \"\"\"\n    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load image with unchanged flag (to keep RGBA if present)\n\n    # Check if the image was loaded correctly\n    if img is None:\n        print(f\"Failed to load image: {image_path}\")\n        return\n\n    print(f\"Image shape: {img.shape}\")\n\n    # Loop through the provided coordinates and print the pixel values\n    for (x, y) in coordinates:\n        # Ensure the coordinates are within image bounds\n        if y < img.shape[0] and x < img.shape[1]:\n            pixel_value = img[y, x]  # Note that NumPy uses (row, column) -> (y, x)\n            print(f\"Pixel at (x={x}, y={y}): {pixel_value}\")\n        else:\n            print(f\"Coordinates (x={x}, y={y}) are out of bounds for this image.\")\n            \n# Example usage:\n# print_pixel_values('../input_png/SISS2015_Training/1/1_5_slice_44.png')  # Black image\n# print_pixel_values('../input_png/SISS2015_Training/1/1_5_slice_95.png')  # Non-black image\n\n# Example usage for the image and coordinates:\nimage_path = '../input_png/SISS2015_Training/1/1_5_slice_45.png'\ncoordinates_to_check = [(120 + 13, 88 + 13), (220 + 13, 88 + 13)]  # x, y coordinates\n\nprint_pixel_value_at_coordinates(image_path, coordinates_to_check)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:55.258284Z","iopub.execute_input":"2024-10-22T04:29:55.258886Z","iopub.status.idle":"2024-10-22T04:29:55.274654Z","shell.execute_reply.started":"2024-10-22T04:29:55.258832Z","shell.execute_reply":"2024-10-22T04:29:55.273532Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Image shape: (256, 256, 4)\nPixel at (x=133, y=101): [255 255 255 255]\nPixel at (x=233, y=101): [  0   0   0 255]\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport glob\nimport re\nfrom typing import List, Tuple\n\ndef is_black_mask(image_path: str) -> bool:\n    \"\"\"\n    Check if a mask image is completely black (contains no white pixels).\n    \n    Args:\n        image_path (str): Path to the image file\n        \n    Returns:\n        bool: True if image is completely black, False otherwise\n    \"\"\"\n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if img is None:\n        print(f\"Failed to load image: {image_path}\")\n        return True  # Consider failed loads as black images\n    \n    # Check if any pixel is non-zero (white)\n    return not np.any(img > 0)\n\ndef extract_modality_and_slice(path: str) -> Tuple[int, int]:\n    \"\"\"\n    Extract modality and slice numbers from the image file path.\n    \n    Args:\n        path (str): Path to the image file\n        \n    Returns:\n        Tuple[int, int]: (modality number, slice number)\n    \"\"\"\n    match = re.search(r'_(\\d)_(?:slice_)(\\d+)', path)\n    if match:\n        return int(match.group(1)), int(match.group(2))\n    return -1, -1\n\ndef sort_by_modality_and_slice(paths: List[str]) -> List[str]:\n    \"\"\"\n    Sort paths by modality number and then slice number.\n    \n    Args:\n        paths (List[str]): List of image file paths\n        \n    Returns:\n        List[str]: Sorted list of paths\n    \"\"\"\n    return sorted(paths, key=lambda x: extract_modality_and_slice(x))\n\ndef filter_valid_slices(sample_number: int, base_path: str = \"../input_png/SISS2015_Training\") -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Filter and load valid slices (those with non-black masks) for a given sample.\n    \n    Args:\n        sample_number (int): Sample number to process\n        base_path (str): Base path to the dataset\n        \n    Returns:\n        Tuple[np.ndarray, np.ndarray]: Arrays of filtered modality and mask images\n    \"\"\"\n    # Define path patterns\n    mod_pattern = f\"{base_path}/{sample_number}/{sample_number}_2_slice_*.png\"  # DWI modality (2)\n    msk_pattern = f\"{base_path}/{sample_number}/{sample_number}_5_slice_*.png\"  # Masks (5)\n    \n    # Get and sort paths\n    mod_paths = sort_by_modality_and_slice(glob.glob(mod_pattern))\n    msk_paths = sort_by_modality_and_slice(glob.glob(msk_pattern))\n    \n    if len(mod_paths) != len(msk_paths):\n        raise ValueError(f\"Mismatch in number of modality ({len(mod_paths)}) and mask ({len(msk_paths)}) images\")\n    \n    valid_mod_images = []\n    valid_msk_images = []\n    \n    # Process each pair of images\n    for mod_path, msk_path in zip(mod_paths, msk_paths):\n        if not is_black_mask(msk_path):  # Check if mask contains lesions\n            # Load and append images\n            mod_img = cv2.imread(mod_path, cv2.IMREAD_GRAYSCALE)\n            msk_img = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)\n            \n            if mod_img is not None and msk_img is not None:\n                # Normalize modality image to [0, 1]\n                mod_img = mod_img.astype(float) / 255.0\n                # Binarize mask image\n                msk_img = (msk_img > 0).astype(float)\n                \n                valid_mod_images.append(mod_img)\n                valid_msk_images.append(msk_img)\n    \n    # Convert to numpy arrays\n    if valid_mod_images:\n        return np.stack(valid_mod_images), np.stack(valid_msk_images)\n    return np.empty((0, 256, 256)), np.empty((0, 256, 256))\n\ndef process_all_samples(base_path: str = \"../input_png/SISS2015_Training\") -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Process all samples in the dataset.\n    \n    Args:\n        base_path (str): Base path to the dataset\n        \n    Returns:\n        Tuple[np.ndarray, np.ndarray]: Arrays of all filtered modality and mask images\n    \"\"\"\n    all_mod_images = []\n    all_msk_images = []\n    \n    for sample_num in range(1, 29):  # Process all 28 samples\n        mod_filtered, msk_filtered = filter_valid_slices(sample_num, base_path)\n        \n        if mod_filtered.size > 0:\n            all_mod_images.append(mod_filtered)\n            all_msk_images.append(msk_filtered)\n            \n        print(f\"Sample {sample_num}: Found {len(mod_filtered)} valid slices\")\n    \n    # Concatenate all samples\n    return np.concatenate(all_mod_images), np.concatenate(all_msk_images)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T01:27:50.365960Z","iopub.execute_input":"2024-10-23T01:27:50.366446Z","iopub.status.idle":"2024-10-23T01:27:50.388690Z","shell.execute_reply.started":"2024-10-23T01:27:50.366399Z","shell.execute_reply":"2024-10-23T01:27:50.387634Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# # img_path_pattern = \"../input_png/SISS2015_Training/*/*_[1-4]_slice_*.png\"\n# mod_img_path_pattern = \"../input_png/SISS2015_Training/1/1_[1-4]_slice_*.png\"\n# abs_mod_img_paths = glob.glob(mod_img_path_pattern)\n# abs_mod_img_paths = sort_by_modality_and_slice(abs_mod_img_paths)\n# mod_sample1 = load_images(abs_mod_img_paths)\n# print(len(abs_mod_img_paths), len(mod_sample1))  # print(mod_sample1.shape)\n\n# # img_path_pattern = \"../input_png/SISS2015_Training/*/*_5_slice_*.png\"\n# msk_img_path_pattern = \"../input_png/SISS2015_Training/1/1_5_slice_*.png\"\n# abs_msk_img_paths = glob.glob(msk_img_path_pattern)\n# abs_msk_img_paths = sort_by_modality_and_slice(abs_msk_img_paths)\n# msk_sample1 = load_images(abs_msk_img_paths)\n# print(len(abs_msk_img_paths), len(msk_sample1))  # print(msk_sample1.shape)\n\n# abs_modmsk_paths = list(zip(abs_mod_img_paths[:len(abs_msk_img_paths)], abs_msk_img_paths))\n# # abs_modmsk_paths = [\n# #     (mod_path, mask_path) for mod_path, mask_path in zip(abs_mod_img_paths[:len(abs_msk_img_paths)], abs_msk_img_paths)\n# #     if not is_black_image(mask_path)\n# # ]\n\n# print(*abs_modmsk_paths[:3], sep = \"\\n\")  # first 3\n# print(*abs_modmsk_paths[-3:], sep = \"\\n\")  # last 3\n\n# print(is_black_image('../input_png/SISS2015_Training/1/1_5_slice_44.png'))  # black image check\n# print(is_black_image('../input_png/SISS2015_Training/1/1_5_slice_95.png'))  # non black image check\n\n# img1 = cv2.imread('../input_png/SISS2015_Training/1/1_5_slice_44.png', cv2.IMREAD_UNCHANGED)\n# img2 = cv2.imread('../input_png/SISS2015_Training/1/1_5_slice_95.png', cv2.IMREAD_UNCHANGED)\n\n# print(img1.shape)\n# print(img2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:55.675415Z","iopub.execute_input":"2024-10-22T04:29:55.675924Z","iopub.status.idle":"2024-10-22T04:29:56.714302Z","shell.execute_reply.started":"2024-10-22T04:29:55.675874Z","shell.execute_reply":"2024-10-22T04:29:56.713082Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"616 616\n154 154\n('../input_png/SISS2015_Training/1/1_1_slice_1.png', '../input_png/SISS2015_Training/1/1_5_slice_1.png')\n('../input_png/SISS2015_Training/1/1_1_slice_2.png', '../input_png/SISS2015_Training/1/1_5_slice_2.png')\n('../input_png/SISS2015_Training/1/1_1_slice_3.png', '../input_png/SISS2015_Training/1/1_5_slice_3.png')\n('../input_png/SISS2015_Training/1/1_1_slice_152.png', '../input_png/SISS2015_Training/1/1_5_slice_152.png')\n('../input_png/SISS2015_Training/1/1_1_slice_153.png', '../input_png/SISS2015_Training/1/1_5_slice_153.png')\n('../input_png/SISS2015_Training/1/1_1_slice_154.png', '../input_png/SISS2015_Training/1/1_5_slice_154.png')\nTrue\nTrue\n(256, 256, 4)\n(256, 256, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Path to the image\n# image_path = '../input_png/SISS2015_Training/1/1_1_slice_2.png'\n# # Load the image using OpenCV\n# image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n# # Check if the image was loaded successfully\n# if image is not None:\n#     # Print the dimensions of the image\n#     print(f\"Dimensions of the image {image_path}: {image.shape}\")\n# else:\n#     print(f\"Failed to load the image. Please check the file path: {image_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:56.717542Z","iopub.execute_input":"2024-10-22T04:29:56.717979Z","iopub.status.idle":"2024-10-22T04:29:56.723088Z","shell.execute_reply.started":"2024-10-22T04:29:56.717936Z","shell.execute_reply":"2024-10-22T04:29:56.721793Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Paths and dataset\n# PNG_TRAIN_DATASET_PATH = '../input_png/SISS2015_Training/'\n# MASK_MOD_INDEX = 5  # Index for the mask modality in mod_dict (5 corresponds to `.OT.`)\n# # IMG_SIZE = 192\n# PADDED_IMG_SIZE = 256\n\n# # Augmentation parameters\n# augmentation_params = {\n#     \"rotation_range\": 30,\n#     \"width_shift_range\": 0.1,\n#     \"height_shift_range\": 0.1,\n#     \"zoom_range\": 0.2,\n# #     \"sheer_range\": 0.2,\n#     \"horizontal_flip\": True,\n#     \"vertical_flip\": True,\n#     \"fill_mode\": 'nearest'\n# }\n\n# # Initialize ImageDataGenerator with augmentation parameters\n# datagen = ImageDataGenerator(**augmentation_params)\n\n# # Function to load images from a specific path\n# def load_images(image_paths):\n#     images = []\n#     for img_path in image_paths:\n#         img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n#         if img is not None:\n#             images.append(img)\n#     return np.array(images)\n\n\n# # Function to get paths for lesion and non-lesion images based on mask files\n# def get_lesion_non_lesion_image_paths():\n#     lesion_paths, non_lesion_paths = [], []\n#     for i in range(1, 29):  # Loop through each sample\n#         image_dir = f\"{PNG_TRAIN_DATASET_PATH}{i}/\"\n#         mask_files = [f for f in os.listdir(image_dir) if f\"_5_\" in f]  # Get all mask files (modality 5)\n#         for mask_file in mask_files:\n#             mask_path = os.path.join(image_dir, mask_file)\n#             mask_image = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n#             # Correctly extract slice number from mask_file\n#             slice_number = mask_file.split('slice_')[1].split('.')[0]\n#             if mask_image is not None:\n#                 if np.any(mask_image > 0):  # If there is any lesion pixel in the mask\n#                     # Corresponding image files for all 4 modalities\n#                     for modality_index in range(1, 5):  # Modality indexes 1 to 4\n#                         img_path = f\"{image_dir}{i}_{modality_index}_slice_{slice_number}.png\"\n#                         if os.path.exists(img_path):  # Ensure the image path exists\n#                             lesion_paths.append(img_path)\n#                         else:\n#                             print(f\"File not found: {img_path}\")\n#                 else:\n#                     for modality_index in range(1, 5):  # Modality indexes 1 to 4\n#                         img_path = f\"{image_dir}{i}_{modality_index}_slice_{slice_number}.png\"\n#                         if os.path.exists(img_path):  # Ensure the image path exists\n#                             non_lesion_paths.append(img_path)\n#                         else:\n#                             print(f\"File not found: {img_path}\")\n#     return lesion_paths, non_lesion_paths\n\n\n# # Function to augment images and save them\n# def augment_images(image_paths, save_path):\n#     images = load_images(image_paths)\n#     augmented_count = 0\n\n#     for img in images:\n#         img = img.reshape((1,) + img.shape + (1,))  # Reshape for Keras\n\n#         for batch in datagen.flow(img, batch_size=1):\n#             augmented_image = batch[0].reshape(PADDED_IMG_SIZE, PADDED_IMG_SIZE)\n#             cv2.imwrite(f\"{save_path}/augmented_{augmented_count}.png\", augmented_image)\n#             augmented_count += 1\n#             if augmented_count >= len(image_paths):\n#                 break\n\n# # Ensure directories for saving augmented images exist\n# os.makedirs(f\"{PNG_TRAIN_DATASET_PATH}augmented/lesions\", exist_ok=True)\n# os.makedirs(f\"{PNG_TRAIN_DATASET_PATH}augmented/non_lesions\", exist_ok=True)\n\n# # Main process to balance dataset\n# lesion_paths, non_lesion_paths = get_lesion_non_lesion_image_paths()\n\n# # Determine which class needs augmentation\n# if len(lesion_paths) < len(non_lesion_paths):\n#     print(\"Augmenting lesion images to balance the dataset...\")\n#     augment_images(lesion_paths, save_path=f\"{PNG_TRAIN_DATASET_PATH}augmented/lesions\")\n# else:\n#     print(\"Augmenting non-lesion images to balance the dataset...\")\n#     augment_images(non_lesion_paths, save_path=f\"{PNG_TRAIN_DATASET_PATH}augmented/non_lesions\")\n\n# print(\"Data augmentation completed!\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:56.724945Z","iopub.execute_input":"2024-10-22T04:29:56.725438Z","iopub.status.idle":"2024-10-22T04:29:56.746498Z","shell.execute_reply.started":"2024-10-22T04:29:56.725386Z","shell.execute_reply":"2024-10-22T04:29:56.745087Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# augmented_lesion_img_path = f\"{PNG_TRAIN_DATASET_PATH}augmented/lesions\"\n# augmented_non_lesion_img_path = f\"{PNG_TRAIN_DATASET_PATH}augmented/non_lesions\"\n# print(\"Lesion Images Path: \", augmented_lesion_img_path)\n# print(\"Non Lesion Images Path: \", augmented_non_lesion_img_path)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:56.748100Z","iopub.execute_input":"2024-10-22T04:29:56.748986Z","iopub.status.idle":"2024-10-22T04:29:56.759809Z","shell.execute_reply.started":"2024-10-22T04:29:56.748928Z","shell.execute_reply":"2024-10-22T04:29:56.758408Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from PIL import Image\n\n# temp = list(os.listdir(\"../input_png/SISS2015_Training/augmented/\"))\n# print(temp)\n\n# temp = list(os.listdir(\"../input_png/SISS2015_Training/augmented/lesions/\"))\n# # print(temp)\n\n# # Load and display the image\n# image_path = os.path.join(\"../input_png/SISS2015_Training/augmented/lesions/\", temp[3])\n# image = Image.open(image_path).convert('L')  # Convert to grayscale if needed\n# plt.imshow(image, cmap='gray')\n# plt.axis('off')  # Optional: turn off axis labels\n# plt.show()\n\n# with Image.open(image_path) as img:  # Open the image file\n#     width, height = img.size  # Get image dimensions\n#     print(f\"Width: {width}, Height: {height}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T04:29:56.761325Z","iopub.execute_input":"2024-10-22T04:29:56.761767Z","iopub.status.idle":"2024-10-22T04:29:56.769601Z","shell.execute_reply.started":"2024-10-22T04:29:56.761702Z","shell.execute_reply":"2024-10-22T04:29:56.768373Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n\n# class DiffusionModel(nn.Module):\n#     def __init__(self, input_channels=1, hidden_dims=64):\n#         super().__init__()\n#         # Encoder\n#         self.encoder = nn.Sequential(\n#             nn.Conv2d(input_channels, hidden_dims, 3, padding=1),\n#             nn.BatchNorm2d(hidden_dims),\n#             nn.ReLU(),\n#             nn.Conv2d(hidden_dims, hidden_dims*2, 3, padding=1),\n#             nn.BatchNorm2d(hidden_dims*2),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2)\n#         )\n        \n#         # Decoder \n#         self.decoder = nn.Sequential(\n#             nn.ConvTranspose2d(hidden_dims*2, hidden_dims, 2, stride=2),\n#             nn.BatchNorm2d(hidden_dims),\n#             nn.ReLU(),\n#             nn.Conv2d(hidden_dims, input_channels, 3, padding=1),\n#             nn.Sigmoid()\n#         )\n        \n#     def forward(self, x, noise_level):\n#         # Add noise based on noise level\n#         noise = torch.randn_like(x) * noise_level\n#         noisy_x = x + noise\n        \n#         # Encode-decode\n#         encoded = self.encoder(noisy_x)\n#         decoded = self.decoder(encoded)\n        \n#         return decoded\n\n#     def generate(self, num_samples, device):\n#         # Generate samples from random noise\n#         noise = torch.randn(num_samples, 1, 256, 256).to(device)\n#         samples = self.decoder(self.encoder(noise))\n#         return samples","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.metrics import confusion_matrix\n\n# class ValidationMetrics:\n#     @staticmethod\n#     def dice_coefficient(y_true, y_pred):\n#         intersection = np.sum(y_true * y_pred)\n#         return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred))\n    \n#     @staticmethod\n#     def iou_score(y_true, y_pred):\n#         intersection = np.sum(y_true * y_pred)\n#         union = np.sum(y_true) + np.sum(y_pred) - intersection\n#         return intersection / union\n    \n#     @staticmethod \n#     def evaluate_anatomical_correctness(synthetic_images, real_images):\n#         \"\"\"\n#         Evaluate anatomical correctness of synthetic images compared to real ones\n#         \"\"\"\n#         # Add intensity distribution checks\n#         synthetic_mean = np.mean(synthetic_images)\n#         real_mean = np.mean(real_images)\n#         intensity_diff = abs(synthetic_mean - real_mean)\n        \n#         # Add structural similarity checks\n#         structure_score = np.corrcoef(synthetic_images.flatten(), \n#                                     real_images.flatten())[0,1]\n                                    \n#         return {\n#             'intensity_difference': intensity_diff,\n#             'structural_similarity': structure_score\n#         }\n        \n#     def evaluate_out_of_distribution(self, model, ood_data):\n#         \"\"\"\n#         Evaluate model performance on out-of-distribution data\n#         \"\"\"\n#         predictions = []\n#         ground_truth = []\n        \n#         for batch in ood_data:\n#             pred = model.predict(batch['image'])\n#             predictions.append(pred)\n#             ground_truth.append(batch['mask'])\n            \n#         # Calculate metrics\n#         dice = self.dice_coefficient(np.array(ground_truth), \n#                                    np.array(predictions))\n#         iou = self.iou_score(np.array(ground_truth),\n#                             np.array(predictions))\n                            \n#         return {\n#             'ood_dice': dice,\n#             'ood_iou': iou\n#         }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # PAPER - Healthcare Analytics\n# # Traditional Augmentation Pipeline highlighted in the paper:\n\n# def augment_medical_image(image, mask=None):\n#     # Geometric transforms\n#     if random.random() > 0.5:\n#         angle = random.randint(-30, 30)\n#         image = rotate(image, angle)\n#         if mask is not None:\n#             mask = rotate(mask, angle)\n    \n#     # Intensity augmentation\n#     if random.random() > 0.5:\n#         image = adjust_brightness(image, factor=random.uniform(0.8, 1.2))\n        \n#     # Elastic deformation\n#     if random.random() > 0.5:\n#         image = elastic_transform(image)\n#         if mask is not None:\n#             mask = elastic_transform(mask)\n            \n#     return image, mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # PAPER - Data Augmentation for Image Classification using Generative AI\n# # Relevant Algorithm - Random Local Rotation:\n\n# def random_local_rotation(image, mask=None):\n#     \"\"\"\n#     RLR algorithm from paper:\n#     1. Select random circular region\n#     2. Rotate only that region\n#     3. Preserve rest of the image\n#     \"\"\"\n#     height, width = image.shape[:2]\n    \n#     # Random center and radius\n#     center_x = random.randint(0, width)\n#     center_y = random.randint(0, height)\n#     max_radius = min(min(center_x, width-center_x), \n#                     min(center_y, height-center_y))\n#     radius = random.randint(max_radius//4, max_radius)\n    \n#     # Create circular mask\n#     Y, X = np.ogrid[:height, :width]\n#     dist_from_center = np.sqrt((X - center_x)**2 + (Y-center_y)**2)\n#     circular_mask = dist_from_center <= radius\n    \n#     # Random rotation angle\n#     angle = random.randint(0, 360)\n    \n#     # Rotate region\n#     M = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n#     rotated = cv2.warpAffine(image, M, (width, height))\n    \n#     # Combine\n#     result = np.where(circular_mask[..., None], rotated, image)\n    \n#     if mask is not None:\n#         rotated_mask = cv2.warpAffine(mask, M, (width, height))\n#         mask_result = np.where(circular_mask, rotated_mask, mask)\n#         return result, mask_result\n        \n#     return result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Data Augmentation in Classification and Segmentation: A Survey and New Strategies\n# # Relevant Algorithm - AGA Pipeline:\n\n# class AGAFramework:\n#     def __init__(self):\n#         self.segmentation_model = load_segmentation_model()\n#         self.diffusion_model = load_diffusion_model()\n#         self.llm = load_language_model()\n        \n#     def generate_augmented_sample(self, image, class_name):\n#         # 1. Generate mask\n#         mask = self.segmentation_model.predict(image)\n        \n#         # 2. Extract subject\n#         subject = image * mask\n        \n#         # 3. Generate background prompt\n#         prompt = self.llm.generate_background_prompt(class_name)\n        \n#         # 4. Generate diverse background\n#         background = self.diffusion_model.generate(prompt)\n        \n#         # 5. Merge subject and background\n#         result = subject + (1-mask) * background\n        \n#         return result","metadata":{},"execution_count":null,"outputs":[]}]}